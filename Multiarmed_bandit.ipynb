{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7EY8+KBp8I8N8Ih3QaoBR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditya312003/E-Commerce-Data-EDA/blob/master/Multiarmed_bandit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_arms = 5\n",
        "\n",
        "num_trials = 1000\n",
        "\n",
        "true_means = np.array([4, 3, 5, 7, 2])\n",
        "\n",
        "estimates = np.ones(num_arms) * 10\n",
        "\n",
        "counts = np.zeros(num_arms)\n",
        "\n",
        "cumulative_reward = 0\n",
        "average_rewards = [0] * num_arms\n",
        "\n",
        "machine_counts = [0] * num_arms\n",
        "\n",
        "# Perform the trials\n",
        "for t in range(1, num_trials + 1):\n",
        "    # Exploration phase (randomly select a machine)\n",
        "    if t <= num_arms:\n",
        "        action = t - 1  # Select each machine once in the initial phase\n",
        "    # Exploitation phase (select the machine with the highest estimated reward)\n",
        "    else:\n",
        "        action = np.argmax(estimates)\n",
        "\n",
        "    reward = np.random.normal(true_means[action], 1)\n",
        "\n",
        "    counts[action] += 1\n",
        "    cumulative_reward += reward\n",
        "\n",
        "    estimates[action] += (reward - estimates[action]) / counts[action]\n",
        "\n",
        "\n",
        "    for arm in range(num_arms):\n",
        "        average_rewards[arm] += (reward - average_rewards[arm]) / t\n",
        "\n",
        "    machine_counts[action] += 1\n",
        "\n",
        "print(f\"Cumulative Reward: {cumulative_reward}\")\n",
        "print(f\"Average Reward: {average_rewards[i]:.2f}\")\n",
        "for i in range(num_arms):\n",
        "    print(f\"Machine {chr(97+i)} - True Mean: {true_means[i]}, Estimated Mean: {estimates[i]:.2f}, \"\n",
        "          f\", number of run : {machine_counts[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR-VddpkbnM9",
        "outputId": "27e94796-de6f-4802-df83-6d54db24fa65"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative Reward: 6937.510792806368\n",
            "Average Reward: 6.94\n",
            "Machine a - True Mean: 4, Estimated Mean: 4.28, , number of run : 1\n",
            "Machine b - True Mean: 3, Estimated Mean: 3.76, , number of run : 1\n",
            "Machine c - True Mean: 5, Estimated Mean: 4.30, , number of run : 1\n",
            "Machine d - True Mean: 7, Estimated Mean: 6.95, , number of run : 996\n",
            "Machine e - True Mean: 2, Estimated Mean: 2.07, , number of run : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_arms = 5\n",
        "num_trials = 1000\n",
        "true_means = np.array([4, 3, 5, 7, 2])\n",
        "\n",
        "# Epsilon for epsilon-greedy strategy\n",
        "epsilon = 0.1\n",
        "\n",
        "estimates = np.ones(num_arms) * 10\n",
        "counts = np.zeros(num_arms)\n",
        "\n",
        "cumulative_reward = 0\n",
        "average_rewards = [0] * num_arms\n",
        "\n",
        "machine_counts = [0] * num_arms\n",
        "\n",
        "# Perform the trials\n",
        "for t in range(1, num_trials + 1):\n",
        "    # Epsilon-greedy action selection\n",
        "    if np.random.rand() < epsilon:\n",
        "        action = np.random.randint(num_arms)  # Explore: choose a random machine\n",
        "    else:\n",
        "        action = np.argmax(estimates)  # Exploit: choose the machine with the highest estimated reward\n",
        "\n",
        "    reward = np.random.normal(true_means[action], 1)\n",
        "\n",
        "    counts[action] += 1\n",
        "    cumulative_reward += reward\n",
        "\n",
        "    estimates[action] += (reward - estimates[action]) / counts[action]\n",
        "\n",
        "    for arm in range(num_arms):\n",
        "        average_rewards[arm] += (reward - average_rewards[arm]) / t\n",
        "\n",
        "    machine_counts[action] += 1\n",
        "\n",
        "print(f\"Cumulative Reward: {cumulative_reward}\")\n",
        "print(f\"Average Reward: {average_rewards[i]:.2f}\")\n",
        "for i in range(num_arms):\n",
        "    print(f\"Machine {chr(97+i)} - True Mean: {true_means[i]}, Estimated Mean: {estimates[i]:.2f}, \"\n",
        "          f\"number of run : {machine_counts[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGidNOTze5NG",
        "outputId": "d3aa8b09-6093-4cf4-c22a-3eb4f9ffd78e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative Reward: 6705.680309301963\n",
            "Average Reward: 6.71\n",
            "Machine a - True Mean: 4, Estimated Mean: 4.04, number of run : 24\n",
            "Machine b - True Mean: 3, Estimated Mean: 2.81, number of run : 19\n",
            "Machine c - True Mean: 5, Estimated Mean: 5.14, number of run : 19\n",
            "Machine d - True Mean: 7, Estimated Mean: 6.99, number of run : 917\n",
            "Machine e - True Mean: 2, Estimated Mean: 2.11, number of run : 21\n"
          ]
        }
      ]
    }
  ]
}